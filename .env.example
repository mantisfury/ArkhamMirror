# =============================================================================
# ArkhamMirror Environment Configuration
# =============================================================================
# Copy this file to .env and update values as needed.
# All values shown are the defaults used if not specified.
#
# RECOMMENDED: Keep this file at PROJECT_ROOT/.env
# The config module also checks arkham_reflex/.env for backward compatibility.

# =============================================================================
# DATABASE (PostgreSQL)
# =============================================================================
# Docker exposes internal 5432 on external 5435
POSTGRES_HOST=localhost
POSTGRES_PORT=5435
POSTGRES_USER=anom
POSTGRES_PASSWORD=anompass
POSTGRES_DB=anomdb

# Full connection URL (overrides individual settings above if set)
DATABASE_URL=postgresql://anom:anompass@localhost:5435/anomdb

# =============================================================================
# VECTOR DATABASE (Qdrant)
# =============================================================================
# Docker exposes internal 6333 on external 6343
QDRANT_HOST=localhost
QDRANT_PORT=6343
QDRANT_URL=http://localhost:6343

# =============================================================================
# QUEUE (Redis)
# =============================================================================
# Docker exposes internal 6379 on external 6380
REDIS_HOST=localhost
REDIS_PORT=6380
REDIS_URL=redis://localhost:6380

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# ArkhamMirror does NOT bundle an LLM. You provide your own inference.
# All providers use OpenAI-compatible API format.
#
# PROVIDER OPTIONS:
#   local      - Local inference (LM Studio, Ollama) [default]
#   openai     - OpenAI API (GPT-4o, etc.)
#   openrouter - OpenRouter (500+ models, pay-per-use)
#   together   - Together AI
#   groq       - Groq (fast inference)
#   azure      - Azure OpenAI
#
LLM_PROVIDER=local

# -----------------------------------------------------------------------------
# LOCAL LLM BACKEND (only used when LLM_PROVIDER=local)
# -----------------------------------------------------------------------------
# Options: lm_studio (default), ollama, vllm (if you run it yourself)
LLM_LOCAL_BACKEND=lm_studio

# Local endpoint URLs (uncomment to override defaults)
# LM_STUDIO_URL=http://localhost:1234/v1
# OLLAMA_URL=http://localhost:11434/v1
# VLLM_URL=http://localhost:8001/v1

# -----------------------------------------------------------------------------
# CLOUD PROVIDER API KEYS (set the one for your chosen provider)
# -----------------------------------------------------------------------------
# OPENAI_API_KEY=sk-...
# OPENROUTER_API_KEY=sk-or-...
# TOGETHER_API_KEY=...
# GROQ_API_KEY=gsk_...
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com

# -----------------------------------------------------------------------------
# MODEL SELECTION (optional - uses sensible defaults per provider)
# -----------------------------------------------------------------------------
# LLM_MODEL=gpt-4o              # For OpenAI
# LLM_MODEL=qwen/qwen3-4b       # For OpenRouter
# LLM_MODEL=llama-3.3-70b       # For Groq

# =============================================================================
# APPLICATION PORTS
# =============================================================================
BACKEND_PORT=8000
FRONTEND_PORT=3000

# =============================================================================
# SECURITY: NETWORK BINDING
# =============================================================================
# By default, ArkhamMirror binds to localhost only (127.0.0.1).
# This prevents anyone on your local network from accessing your instance.
#
# For "Team Mode" (sharing on a trusted LAN), uncomment and set:
# BACKEND_HOST=0.0.0.0
#
# WARNING: Only use 0.0.0.0 on trusted networks! On public WiFi (coffee shops, etc.),
# anyone on that network could access your ArkhamMirror instance.
BACKEND_HOST=127.0.0.1

# =============================================================================
# NETWORK / PRIVACY
# =============================================================================
# Reflex (the web framework) performs an IPv4/IPv6 connectivity check on startup
# by connecting to Cloudflare's public DNS (1.1.1.1 and 2606:4700:4700::1111).
# This can trigger firewall alerts or fail in air-gapped environments.
#
# Setting this variable explicitly skips the auto-detection.
# We use 127.0.0.1 for consistency with our localhost-only security posture.
# For pure IPv6 networks, use "::" instead.
#
# Note: This controls the *outbound* HTTP client bind address (for Reflex's
# Cloudflare connectivity check), NOT server listening. Using 127.0.0.1 here
# is a belt-and-suspenders safety measure, not strictly required.
REFLEX_HTTP_CLIENT_BIND_ADDRESS=127.0.0.1
